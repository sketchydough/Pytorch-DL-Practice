{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBirnEfsdRtsch9alDrkBp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sketchydough/Pytorch-DL-Practice/blob/main/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "xm2Ri-cGxJqO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert mnist image files into a tensor of 4-D (#images,height,width,color channel)\n",
        "transform=transforms.ToTensor()  #changing images to a tensor\n"
      ],
      "metadata": {
        "id": "x6a4S5-Jx_JL"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train data\n",
        "train_data=datasets.MNIST(root='/cnn_data',train=True,download=True,transform=transform)"
      ],
      "metadata": {
        "id": "C0K3C8RnyXc_"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test data\n",
        "test_data=datasets.MNIST(root='/cnn_data',train=False,download=True,transform=transform)"
      ],
      "metadata": {
        "id": "5LzomOYnyq66"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUaHQNb8zGHI",
        "outputId": "075b8900-b3f9-4902-a252-17476c2e92cb"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghG7FctpzJ-Y",
        "outputId": "524f9f25-c7d2-4ede-bcf3-36d338f2f41f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a small batch size for images..let 10\n",
        "train_loader= DataLoader(train_data,batch_size=10,shuffle=True)\n",
        "test_loader= DataLoader(test_data,batch_size=10,shuffle=False)"
      ],
      "metadata": {
        "id": "FOUYI6kIzosN"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define our cnn model\n",
        "#describe convolutional layer and what its doing (2 convolutional layers)\n",
        "\n",
        "conv1=nn.Conv2d(1,6,3,1) #input images,#convolutional layers, #kernal 3x3 size, stride one ata time\n",
        "conv2=nn.Conv2d(6,16,3,1) #here 6 inputd cuz from prev conv we get 6 o/p, 16 convolutional layers, 3x3 kernal, 1 o/p"
      ],
      "metadata": {
        "id": "VwDbQxky3gCw"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grab 1 mnist record/image\n",
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "  break"
      ],
      "metadata": {
        "id": "9ZCJBkUz4jLt"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXkAWu514xyx",
        "outputId": "e70bef7a-0a6b-4b78-9dc0-b20ca3c0a0a2"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x0UcH0k41mS",
        "outputId": "a0099611-38c4-41b1-f1a4-db4be02dc646"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changing it to 4d\n",
        "x=X_train.view(1,1,28,28)"
      ],
      "metadata": {
        "id": "csfeHS0u47LQ"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform our first convolution\n",
        "x=F.relu(conv1(x)) #rectified linear unit for our activation function"
      ],
      "metadata": {
        "id": "JdlVX-_25C3e"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #1 single image, 6 filters we asked for, 26x26 ? cuz it shrinks since we didnt set the padding when we defined our model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbLFgFCL5Qsv",
        "outputId": "df6e43e7-dbec-4400-d1ca-422d30194e08"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pass thru the pooling layer\n",
        "x=F.max_pool2d(x,2,2) #kernal of 2 and stride of 2"
      ],
      "metadata": {
        "id": "RtDKL1pO5SUh"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #13 cuz we set the kernal and stride of 2 for pooling  26/2=13\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYLpBDfk6OHU",
        "outputId": "62fff149-407e-43ae-fda3-287d5fccae60"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets do our second convolutional layer\n",
        "x=F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "zI-Bgeqw6QZG"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 13x13 and since we didnt set any padding ->so we loose 2 pxels around the outside of the image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNMFQjoP6qM1",
        "outputId": "a017ae2e-5863-4568-9996-537ffff12448"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pooling layer\n",
        "x=F.max_pool2d(x,2,2)"
      ],
      "metadata": {
        "id": "BWlFku0S6vdV"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #11/2=5.5 but we have to round down, bco you cant invent data to round up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq4fE-786_E8",
        "outputId": "dc18a024-39ec-44e6-dace-bf38410e8a29"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model class\n",
        "\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1= nn.Conv2d(1,6,3,1)\n",
        "    self.conv2= nn.Conv2d(6,16,3,1)\n",
        "    #fully connected layer\n",
        "    self.fc1=nn.Linear(5*5*16,120) #flattening out to 120 neurons\n",
        "    self.fc2=nn.Linear(120,84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "\n",
        "    #need a forward function to define the layout\n",
        "  def forward(self,X):\n",
        "    X=F.relu(self.conv1(X))\n",
        "    X=F.max_pool2d(X,2,2) #2x2 kernal and stride 2\n",
        "    #second pass\n",
        "    X=F.relu(self.conv2(X))\n",
        "    X=F.max_pool2d(X,2,2)\n",
        "\n",
        "      #re-view to flatten it out\n",
        "    X=X.view(-1, 16*5*5) #negative one so that we can vary the batch size\n",
        "\n",
        "      #fully connected layers\n",
        "    X=F.relu(self.fc1(X))\n",
        "    X=F.relu(self.fc2(X))\n",
        "    X=self.fc3(X)\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "V5SjDQXP7BBc"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an instance of our model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_NePEZJBOEP",
        "outputId": "8cba29e5-13cf-45ad-a6ba-0d2168c877d2"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function optimizer\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.01) #smaller the learnign rate, longer its gonna take to train"
      ],
      "metadata": {
        "id": "f_Ylal7LBayY"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time # to see how long this takes\n",
        "start_time= time.time()\n",
        "\n",
        "#create variables to track things\n",
        "epochs=5\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "test_correct=[]\n",
        "train_correct=[]\n",
        "\n",
        "#For loop of epochs\n",
        "for i in range(epochs):\n",
        "  train_corr=0\n",
        "  test_corr=0\n",
        "\n",
        "  #Train\n",
        "  for b,(X_train,y_train) in enumerate(train_loader):\n",
        "    b+=1 #start batches at 1\n",
        "    y_pred =model(X_train) #get predicted value from the trianing set. not flattened, its 2d\n",
        "    loss= criterion(y_pred,y_train) #calulate loss\n",
        "\n",
        "    predicted=torch.max(y_pred.data, 1)[1] #add up the number of correct predictions. indexed off the first point\n",
        "    batch_corr=(predicted == y_train).sum() #how many we got correct from this batch. true=1,false=0 and sum it up\n",
        "    train_corr += batch_corr #add up the number of correct predictions\n",
        "\n",
        "    #update parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #print results\n",
        "    if b%600==0:\n",
        "      print(f'epoch: {i} batch: {b} loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(train_corr)\n",
        "\n",
        "  #Test\n",
        "  with torch.no_grad(): #no grad so we dont update our weights and biases with test data\n",
        "    for b,(X_test,y_test) in enumerate(test_loader):\n",
        "      y_val=model(X_test)\n",
        "      predicted=torch.max(y_val.data,1)[1] #adding up correct predictions\n",
        "      test_corr += (predicted == y_test).sum() # T=1 F=0 and sum it away\n",
        "\n",
        "  loss=criterion(y_val,y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(test_corr)\n",
        "\n",
        "\n",
        "\n",
        "current_time=time.time()\n",
        "total=current_time-start_time\n",
        "print(f'Training took: {total/60} minutes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foSV9P4WBsL3",
        "outputId": "12f1a500-ed11-484c-e24d-97641dd03b1a"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 batch: 600 loss: 0.3602105975151062\n",
            "epoch: 0 batch: 1200 loss: 0.26941999793052673\n",
            "epoch: 0 batch: 1800 loss: 0.0018595507135614753\n",
            "epoch: 0 batch: 2400 loss: 0.09844367951154709\n",
            "epoch: 0 batch: 3000 loss: 1.2523682117462158\n",
            "epoch: 0 batch: 3600 loss: 0.014283351600170135\n",
            "epoch: 0 batch: 4200 loss: 0.02023053541779518\n",
            "epoch: 0 batch: 4800 loss: 0.42354097962379456\n",
            "epoch: 0 batch: 5400 loss: 0.22341743111610413\n",
            "epoch: 0 batch: 6000 loss: 0.05625303462147713\n",
            "epoch: 1 batch: 600 loss: 0.00150180677883327\n",
            "epoch: 1 batch: 1200 loss: 0.0004955746699124575\n",
            "epoch: 1 batch: 1800 loss: 0.2673165202140808\n",
            "epoch: 1 batch: 2400 loss: 1.3810557126998901\n",
            "epoch: 1 batch: 3000 loss: 0.0004503824166022241\n",
            "epoch: 1 batch: 3600 loss: 0.09446550160646439\n",
            "epoch: 1 batch: 4200 loss: 0.000286845926893875\n",
            "epoch: 1 batch: 4800 loss: 0.23478055000305176\n",
            "epoch: 1 batch: 5400 loss: 0.006459338124841452\n",
            "epoch: 1 batch: 6000 loss: 0.31828704476356506\n",
            "epoch: 2 batch: 600 loss: 0.23991870880126953\n",
            "epoch: 2 batch: 1200 loss: 0.00720601761713624\n",
            "epoch: 2 batch: 1800 loss: 0.09631162136793137\n",
            "epoch: 2 batch: 2400 loss: 0.3671339750289917\n",
            "epoch: 2 batch: 3000 loss: 0.031040722504258156\n",
            "epoch: 2 batch: 3600 loss: 0.4370487332344055\n",
            "epoch: 2 batch: 4200 loss: 0.5328131914138794\n",
            "epoch: 2 batch: 4800 loss: 0.08409147709608078\n",
            "epoch: 2 batch: 5400 loss: 0.0161423459649086\n",
            "epoch: 2 batch: 6000 loss: 0.21505126357078552\n",
            "epoch: 3 batch: 600 loss: 8.391942537855357e-05\n",
            "epoch: 3 batch: 1200 loss: 1.1357486248016357\n",
            "epoch: 3 batch: 1800 loss: 0.00043409824138507247\n",
            "epoch: 3 batch: 2400 loss: 0.03358357772231102\n",
            "epoch: 3 batch: 3000 loss: 0.5506418347358704\n",
            "epoch: 3 batch: 3600 loss: 0.009446734562516212\n",
            "epoch: 3 batch: 4200 loss: 0.4112904965877533\n",
            "epoch: 3 batch: 4800 loss: 0.566217303276062\n",
            "epoch: 3 batch: 5400 loss: 0.12979812920093536\n",
            "epoch: 3 batch: 6000 loss: 0.0750056579709053\n",
            "epoch: 4 batch: 600 loss: 0.18090283870697021\n",
            "epoch: 4 batch: 1200 loss: 0.015108989551663399\n",
            "epoch: 4 batch: 1800 loss: 0.0011863166000694036\n",
            "epoch: 4 batch: 2400 loss: 3.017942071892321e-05\n",
            "epoch: 4 batch: 3000 loss: 0.09055522084236145\n",
            "epoch: 4 batch: 3600 loss: 0.17136402428150177\n",
            "epoch: 4 batch: 4200 loss: 0.009920408949255943\n",
            "epoch: 4 batch: 4800 loss: 0.0012911974918097258\n",
            "epoch: 4 batch: 5400 loss: 0.006293890066444874\n",
            "epoch: 4 batch: 6000 loss: 0.3699851632118225\n",
            "Training took: 3.8428959528605144 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PT8CBzhTKN7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}